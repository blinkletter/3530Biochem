{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Enzyme Kinetics\n",
    "\n",
    "In this workbook we will introduce simple *Python* commands for plotting enzyme kinetics.\n",
    "\n",
    "The famous Michaelis-menten equation is...\n",
    "\n",
    "$$ \\nu = V_{max} \\frac{[S]}{K_M + [S]} $$\n",
    "\n",
    "It describes a hyperbolic curve and there is no curve fit available in the presets in Microsoft Excel or Google Sheets that describes this function. \n",
    "\n",
    "It can be written in linear form as the abominable Lineweaver-Burke equation...\n",
    "\n",
    "$$ \\frac{1}{\\nu} = \\frac{1}{V_{max}} + \\frac{K_M}{V_{max}}\\frac{1}{[S]} $$\n",
    "\n",
    "\n",
    "Below we will plot a data set from problem 7.7 in the textbook. \n",
    "\n",
    "## Setting Up the Data\n",
    "\n",
    "The code below creates assignments for variables states in the problem and makes an array of the experimental data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "########################\n",
    "## Problem 7.7\n",
    "########################\n",
    "\n",
    "\n",
    "#######################\n",
    "## Facts from problem\n",
    "#######################\n",
    "\n",
    "mw_enzyme = 29600 ## g/mole \n",
    "g_enzyme = 1E-9   ## g  -  amount of enzyme added to tube\n",
    "volume = 10       ## mL -  volume of solution\n",
    "time = 1          ## min. - time period at observation\n",
    "\n",
    "### Table of concentration of penicillin (substrate) and amount consumed after time period\n",
    "\n",
    "### Conc (uM), nanomoles\n",
    "data = [[1,   0.11],\n",
    "        [3,   0.25],\n",
    "        [5,   0.34],\n",
    "        [10,  0.45],\n",
    "        [30,  0.58],\n",
    "        [50,  0.61]]\n",
    "\n",
    "\n",
    "##########################################################\n",
    "### Calculate the rates of reaction from the data.\n",
    "##########################################################\n",
    "\n",
    "import numpy as np                    ## import the tools of NumPy but use a shorter name\n",
    "\n",
    "data = np.array(data)   ### Convert the above list of lists to a 2D array.\n",
    "\n",
    "### Collect concentrations and amount reacted data as two separate arrays\n",
    "\n",
    "conc_penicillin = data[:,0]   ### uM     - all rows, column 0\n",
    "amount_hydrolyzed = data[:,1] ### nmoles - all rows, column 1\n",
    "\n",
    "### I could have just created the data set as two separate lists. \n",
    "### But I used a list of data pairs (a list of lists) and then\n",
    "### converted it to an n x 2 array (columns of data).\n",
    "\n",
    "# rate = nanomoles / (mL * 1L/1000mL) / (minutes *  60 seconds/minute)\n",
    "rate = amount_hydrolyzed / (volume * (1/1000)) / (time * 60/1)  ## nanomoles/L/second\n",
    "\n",
    "x = conc_penicillin\n",
    "y = rate\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Simple Plot\n",
    "\n",
    "We now have a set of x and y data. We know what x and y are because we can examine the code and see (x is the substrate concentration, y is the rate of the enzyme-catalyzed reaction.)\n",
    "\n",
    "Plotting is easy in *Python*. We will use the *MatPlotLib* package. It is a very powerful plotting tool. Within it is the *MatPlotLib.PyPlot* sublibrary, which provides tools that are simple to use for plotting. \n",
    "\n",
    "The code below will plot the x,y data we established above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt    ## import the tools of MatPlotLib.PyPlot but use a shorter name\n",
    "\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Data\n",
    "\n",
    "Perhaps the above plot is a little too basic? We could add some style using commands built into the *MatPlotLib.PyPlot* system. Remember we have named *PyPlot* as \"*plt*\" in the code below (see the very first two lines of code in the block above)\n",
    "\n",
    "### A Michaelis-Menten Plot\n",
    "Below is code to plot the x,y data. You can use this code top plot any x,y data. Just steal it and change it to suit you. The first command resets all the defaults so that any changes you make are starting from the same place every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "######################\n",
    "### Create an empty plot\n",
    "#####################\n",
    "\n",
    "plt.rcdefaults()           ### Reset default style - no needed but just in case.\n",
    "plt.figure(figsize=(5,4))  ### establish a figure with size 5x4\n",
    "\n",
    "######################\n",
    "### Plot the data\n",
    "#####################\n",
    "\n",
    "plt.plot(x, y, \"ko\")      ### 'k' is black, 'o' is 'circles', '-' is solid line. \n",
    "                          ### Try \"g.\", \"ko-\", \"ro--\", \"b^-\"\n",
    "\n",
    "######################\n",
    "### Add some style\n",
    "######################\n",
    "\n",
    "plt.ylim(0, None)         ### y-axis limits are min = 0, max = whatever\n",
    "plt.xlim(0, None)         ### x-axis limits are min = 0, max = whatever\n",
    "\n",
    "plt.ylabel(r\"$\\nu\\ \\ /\\,nM\\: s^{-1}$\")   ### The $ indicates \"math typesetting language\"\n",
    "plt.xlabel(r\"$[S]\\ \\ /\\,\\mu M$\")\n",
    "plt.title(\"Michaelis-Menten Plot\")\n",
    "\n",
    "######################\n",
    "### Display and export the plot\n",
    "######################\n",
    "\n",
    "#plt.savefig(\"MM_plot.pdf\")    ### Save the image as a pdf file. Now you can use it in a document.\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Double Reciprocol Plot\n",
    "\n",
    "We can plot the Lineweaver-Burke plot by taking the reciprocals of our data and just steal the code as above. I changed style details (title, axis labels, axis ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "######################\n",
    "### reciprocol calculations\n",
    "#####################\n",
    "\n",
    "x_lb = 1/x\n",
    "y_lb = 1/y\n",
    "\n",
    "####################################################\n",
    "### Steal code above and re-use it\n",
    "####################################################\n",
    "\n",
    "######################\n",
    "### Create an empty plot\n",
    "#####################\n",
    "\n",
    "plt.rcdefaults()           ### Reset default style - no needed but just in case.\n",
    "plt.figure(figsize=(5,4))  ### establish a figure with size 5x4\n",
    "\n",
    "######################\n",
    "### Plot the data\n",
    "#####################\n",
    "\n",
    "plt.plot(x_lb, y_lb, \"ko\")\n",
    "\n",
    "######################\n",
    "### Add some style\n",
    "#####################\n",
    "\n",
    "plt.ylim(0, None)\n",
    "plt.xlim(0, None)\n",
    "\n",
    "plt.ylabel(r\"$\\frac{1}{\\nu\\ /nM\\; s^{-1}}$\")\n",
    "plt.xlabel(r\"$\\frac{1}{[S]\\ /\\mu M}$\")\n",
    "plt.ylabel(r\"$1/(\\nu\\ /nM\\; s^{-1})$\")\n",
    "plt.xlabel(r\"$1/([S]\\ /\\mu M)$\")\n",
    "plt.title(\"Lineweaver-Burke Plot\")\n",
    "\n",
    "######################\n",
    "### Display and export the plot\n",
    "#####################\n",
    "\n",
    "#plt.savefig(\"LB_plot.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Curve Fitting\n",
    "\n",
    "Various *Python* tools can perform least squares fits to a given function. There are many ways to do this. We will consider only one way. We will use the tools in the *SciPy* package.\n",
    "\n",
    "*SciPy* is a library of tools for scientific computing. One set of tools is the *SciPy.Optimize* sublibrary. It provides many tools for statistical analysis of data. We will be using the *SciPy.Optimize.Curve_Fit* function. \n",
    "\n",
    "First we must define a function to which we will fit a set of x,y data. Then we can send that function and the x,y sata to the *Curve_Fit* function. We will get back two data objects. One will be the best values of the parameters (e.g. slope and intercept) and the other is a set of statistical information.\n",
    "\n",
    "### Define Functions\n",
    "In the code below I will define two functions. A linear function, with slope and intercept, and a function that describes the Michaelis-Menten model, with $V_{max}$ and $K_M$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "####################################\n",
    "### define a linear function\n",
    "####################################\n",
    "\n",
    "def linear(x, slope, intercept):  ### Take x values, slope and intercept and return the y values\n",
    "    y = slope * x + intercept\n",
    "    return(y)\n",
    "\n",
    "####################################\n",
    "### define a Michaelis-Menten function\n",
    "####################################\n",
    "\n",
    "def MMplot(S, Vmax, KM):\n",
    "    v = Vmax * S / (S + KM)\n",
    "    return(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Linear Curve Fit\n",
    "\n",
    "The code below will fit the Lineweaver-Burke double reciprocol plot data to a linear function. We will then get the parameters for the lone and the standard error calculated by the *SciPy.optimize.curve_fit* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "print_all = False   ## True or False\n",
    "####################################\n",
    "### Perform the curve fit\n",
    "####################################\n",
    "\n",
    "params, stats = curve_fit(linear, x_lb, y_lb)   ## two objects are returned\n",
    "\n",
    "####################################\n",
    "### Print the two objects that are returned\n",
    "####################################\n",
    "\n",
    "if print_all:\n",
    "    print(f\"the params object contains...\")\n",
    "    display(params)\n",
    "    print(\"which is the slope and the intercept\")\n",
    "    print()\n",
    "    print(f\"the stats object contains...\")\n",
    "    display(stats)\n",
    "    print(\"which is the covariance matrix and can be used to calculate \\nthe standard deviations in the parameters.\")\n",
    "    print()\n",
    "\n",
    "####################################\n",
    "### Interpret the results\n",
    "####################################\n",
    "\n",
    "slope, intercept = params   ### pull out the two values in the params object\n",
    "\n",
    "perr = np.sqrt(np.diag(stats))        ### convert covariance matrix to stdev values\n",
    "stdev_slope, stdev_intercept = perr   ### pull out the two stdev values \n",
    "\n",
    "print(f\"The slope is {slope:0.2f} +/- {stdev_slope:0.2f}\")\n",
    "print(f\"The intercept is {intercept:0.2f} +/- {stdev_intercept:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Uncertainties\n",
    "\n",
    "The curve fit function estimated the error in your data based on the scatter from the line of the curve fit. But $K_M$ and $V_{max}$ are reciprocals of these values. How do you handle error propagation in reciprocals? I don't know either, but *Python* can import tools that do.\n",
    "\n",
    "We will need to install the *Uncertainties* package, which is not part of the standard library. In Colab you will need to install it by \"uncommenting the line of code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "####################################\n",
    "### Install UNCERTAINTIES package \n",
    "####################################\n",
    "\n",
    "#!pip install uncertainties  # to install in Colab. Add it back to avoid installing again and again.\n",
    "\n",
    "####################################\n",
    "### Import versions of NumPy and Math that use uncertainty \n",
    "####################################\n",
    "\n",
    "import uncertainties as un\n",
    "from uncertainties import unumpy as unp\n",
    "from uncertainties import umath as um\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the tools in the *Uncertainties* package to handle all our error propagation. First we will take the values for the parameters and their standard deviations and create combine objects that include both the value and the uncertainties. \n",
    "\n",
    "The code below will create values that include uncertainties using the *Uncertainties.ufloat* function. It creates a special kind of floating point number that includes the value and its uncertainty. Then we can calculate the values for $V_{max}$ and $K_M$ while also propagating the error. \n",
    "\n",
    "*Note: There are several competing ideas of how to correctly propagate error (although I must admit they all agree at the simple level of arithmatic). How can we document the methods we used? We just show code where we are using the* Uncertainties *package and the tools it contains. Then everyone will know what we did.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "slope_u = un.ufloat(slope,stdev_slope)               ## create a value with uncertainty built in\n",
    "intercept_u = un.ufloat(intercept,stdev_intercept)  \n",
    "\n",
    "print(f\"The slope is {slope_u:0.2f}\")         ## Observe that the single variable now combines the value and the uncertainty\n",
    "print(f\"The intercept is {intercept_u:0.2f}\")\n",
    "print()\n",
    "\n",
    "v_max = 1 / intercept_u\n",
    "KM = v_max * slope_u\n",
    "\n",
    "print(f\"The Vmax is {v_max:0.3f} uM/s\")         ## Observe that the single variable now combines the value and the uncertainty\n",
    "print(f\"The KM is {KM:0.3f} mM\")\n",
    "\n",
    "###################################\n",
    "### Note: We can put back out the value and the error into separate numbers as so...\n",
    "###################################\n",
    "\n",
    "value = unp.nominal_values(v_max)\n",
    "stdev = unp.std_devs(v_max)\n",
    "\n",
    "print()\n",
    "print(f\"We can separate the uncertain value into its nominal value and its stderr\")\n",
    "print(f\"The nominal value for Vmax is {value:0.3f}\")\n",
    "print(f\"The stderr for Vmax is {stdev:0.3f}\")\n",
    "\n",
    "true_slope = 4.57   ### Results of LB curve fit\n",
    "true_intercept = 0.88\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include the Curve Fit in the Plot\n",
    "\n",
    "Let us now add the line that represents the curve fit to the plot.  We will steal the code for plotting the data and then add a plot of the line created using the parameters from the *curve_fit* function results. The code below will repeat the data plot and add the extra line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "################################\n",
    "### make a list of x values from zero to the end of the line\n",
    "################################\n",
    "\n",
    "x_fit = np.linspace(0, np.max(x_lb), 100)  ## 100 points from 0 to the highest value on LB plot x-axis\n",
    "\n",
    "################################\n",
    "### Feed that list into the function for the line fit\n",
    "################################\n",
    "\n",
    "y_fit = linear(x_fit,slope,intercept)\n",
    "\n",
    "################################\n",
    "### Steal the plot code from above and add a line to plot the calculated line fit\n",
    "################################\n",
    "\n",
    "######################\n",
    "### Create an empty plot\n",
    "#####################\n",
    "\n",
    "plt.rcdefaults()           \n",
    "plt.figure(figsize=(5,4))  \n",
    "\n",
    "######################\n",
    "### Plot the data\n",
    "#####################\n",
    "\n",
    "plt.plot(x_lb, y_lb, \"ko\")\n",
    "                               ###########################\n",
    "plt.plot(x_fit, y_fit, \"k-\")   ### This is the extra line\n",
    "                               ###########################\n",
    "######################\n",
    "### Add some style\n",
    "#####################\n",
    "\n",
    "plt.ylim(0, None)\n",
    "plt.xlim(0, None)\n",
    "\n",
    "plt.ylabel(r\"$1\\,/\\,(\\nu\\ /nM\\; s^{-1})$\")\n",
    "plt.xlabel(r\"$1\\,/\\;([S]\\ /\\mu M)$\")\n",
    "plt.title(\"Lineweaver-Burke Plot\")\n",
    "\n",
    "######################\n",
    "### Display and export the plot\n",
    "#####################\n",
    "\n",
    "#plt.savefig(\"LB_plot.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curve Fit the MM Data\n",
    "\n",
    "We will now steal the code above and reuse it. We will change the function that we feed to the *curve_fit* tool to the MMplot() function we defined for the Michaelis-Menten model. We will also make some other changes as needed. For example, this function uses $V_{max}$ and $K_M$ directly and we will not need to do any extra math. And we must use the original data, not the reciprocal data. \n",
    "\n",
    "The code below will make a Michaelis-Menten plot of the data, curve fit it to the MMfit function that describes the model, report the parameters along with their stderr values and plot the curve using the parameteds determines in the curve fit. Everything we did above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "####################################\n",
    "### Perform the curve fit\n",
    "####################################\n",
    "\n",
    "params, stats = curve_fit(MMplot, x, y)   ## two objects are returned\n",
    "\n",
    "####################################\n",
    "### Interpret the results\n",
    "####################################\n",
    "\n",
    "v_max, KM = params   ### pull out the two values in the params object\n",
    "\n",
    "perr = np.sqrt(np.diag(stats))        ### convert covariance matrix to stdev values\n",
    "stdev_v_max, stdev_KM = perr          ### pull out the two stdev values \n",
    "\n",
    "v_max_u = un.ufloat(v_max,stdev_v_max)        ## create a value with uncertainty built in\n",
    "KM_u = un.ufloat(KM,stdev_KM)  \n",
    "\n",
    "print(f\"The Vmax is {v_max_u:0.3f}\")          ## Observe that the single variable now combines the value and the uncertainty\n",
    "print(f\"The KM is {KM_u:0.3f}\")\n",
    "print()\n",
    "\n",
    "################################\n",
    "### make a list of x values from zero to the end of the line\n",
    "################################\n",
    "\n",
    "x_fit = np.linspace(0, np.max(x), 100)  ## 100 points from 0 to the highest value on LB plot x-axis\n",
    "\n",
    "################################\n",
    "### Feed that list into the function for the line fit\n",
    "################################\n",
    "\n",
    "y_fit = MMplot(x_fit,v_max,KM)\n",
    "\n",
    "################################\n",
    "### Steal the plot code from above and add a line to plot the calculated line fit\n",
    "################################\n",
    "\n",
    "######################\n",
    "### Create an empty plot\n",
    "#####################\n",
    "\n",
    "plt.rcdefaults()           \n",
    "plt.figure(figsize=(5,4))  \n",
    "\n",
    "######################\n",
    "### Plot the data and the curve fit line\n",
    "#####################\n",
    "\n",
    "plt.plot(x, y, \"ko\")\n",
    "plt.plot(x_fit, y_fit, \"k-\")   \n",
    "                               \n",
    "######################\n",
    "### Add some style\n",
    "#####################\n",
    "\n",
    "plt.ylim(0, None)\n",
    "plt.xlim(0, None)\n",
    "\n",
    "plt.ylabel(r\"$\\nu\\ \\ /\\,nM\\: s^{-1}$\")   ### The $ indicates \"math typesetting language\"\n",
    "plt.xlabel(r\"$[S]\\ \\ /\\,\\mu M$\")\n",
    "plt.title(\"Michaelis-Menten Plot\")\n",
    "\n",
    "######################\n",
    "### Display and export the plot\n",
    "#####################\n",
    "\n",
    "#plt.savefig(\"MM_plot.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Abomination of LB\n",
    "\n",
    "The Lineweaver-Burke plot is a statistician's nightmare. In the above exercise we determined the $V_{max}$ and $K_M$ for the enzyme/substrate pair presented in the problem given. Let us take the exact same data and apply a slight error to the measured rate of the catalyzed reaction. Every time you run the code in the blocks below you will get a new role of the dice. How often does the Lineweaver-Burke plot come close to the values reported above compared to the curve fit of the Michaelis-Menten data.\n",
    "\n",
    "You can change the magnitude of the error by editing the code. Have some fun.\n",
    "\n",
    "### Random Error in MM Plots\n",
    "\n",
    "The code below will apply an amount of random error to the data in the problem and then I will steal all the code for the MM curve fit and plot from above and use it again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#####################################\n",
    "### Set up Random Number Generator\n",
    "#####################################\n",
    "\n",
    "np.random.seed(228673)   ### We want to seed the generator. Only run this once. \n",
    "                         ### If we repeat the seed ahrad of calling the generator we \n",
    "                         ### will start of with the same series of random numbers. \n",
    "                         ### Computers are never random. they are 'pseudo random'.\n",
    "                         ### That is why the lottery still uses a drum of bouncing balls.\n",
    "\n",
    "### create blank lists to store our random results \n",
    "list_MM_Vmax = []\n",
    "list_MM_KM = []\n",
    "list_LB_Vmax = []\n",
    "list_LB_KM = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#####################################\n",
    "### Explore Effect of Error\n",
    "#####################################\n",
    "\n",
    "### We start with the x,y data entered at the top of this document\n",
    "### Set an error range and then randomly add or subtract the error\n",
    "\n",
    "experimental_error = 0.05   ### error will be +/- this value\n",
    "\n",
    "x2 = x   ## We want to copy the orginal data so that every time we rerun this\n",
    "y2 = y   ##  block of code we are starting agaion with the unchanged original data\n",
    "\n",
    "true_v_max = 1.123   ### Results of MM curve fit\n",
    "true_KM = 5.002\n",
    "\n",
    "number_of_points = len(y2)\n",
    "random_values = np.random.randn(number_of_points) * experimental_error\n",
    "y2 = y2 + random_values\n",
    "\n",
    "########################################################################\n",
    "### Code for MM Plot from Above. Stolen and reused.\n",
    "########################################################################\n",
    "\n",
    "####################################\n",
    "### Perform the curve fit\n",
    "####################################\n",
    "\n",
    "params, stats = curve_fit(MMplot, x2, y2)   ## two objects are returned\n",
    "\n",
    "####################################\n",
    "### Interpret the results\n",
    "####################################\n",
    "\n",
    "v_max, KM = params   ### pull out the two values in the params object\n",
    "\n",
    "perr = np.sqrt(np.diag(stats))        ### convert covariance matrix to stdev values\n",
    "stdev_v_max, stdev_KM = perr          ### pull out the two stdev values \n",
    "\n",
    "v_max_u = un.ufloat(v_max,stdev_v_max)  ## create a value with uncertainty built in\n",
    "KM_u = un.ufloat(KM,stdev_KM)  \n",
    "\n",
    "print(f\"The Vmax is {v_max_u:0.3f}\")      \n",
    "print(f\"The KM is {KM_u:0.3f}\")\n",
    "print()\n",
    "                                    ######################################\n",
    "list_MM_Vmax.append(v_max)          ### Collect results each time this code is run\n",
    "list_MM_KM.append(KM)               ######################################\n",
    "\n",
    "################################\n",
    "### make a list of x values from zero to the end of the line\n",
    "################################\n",
    "\n",
    "x_fit = np.linspace(0, np.max(x2), 100) \n",
    "\n",
    "################################\n",
    "### Feed that list into the function for the line fit\n",
    "################################\n",
    "\n",
    "y_fit = MMplot(x_fit,v_max,KM)\n",
    "\n",
    "######################\n",
    "### Create an empty plot\n",
    "#####################\n",
    "\n",
    "plt.rcdefaults()           \n",
    "plt.figure(figsize=(5,4))  \n",
    "\n",
    "######################\n",
    "### Plot the data and the curve fit line\n",
    "#####################\n",
    "\n",
    "plt.plot(x2, y2, \"ko\")\n",
    "plt.plot(x_fit, y_fit, \"k-\")   \n",
    "                                                           ######################################\n",
    "plt.plot(x_fit, MMplot(x_fit, true_v_max, true_KM), \"r-\")  ### Add in \"ghost line\" for original data\n",
    "                                                           ######################################\n",
    "######################\n",
    "### Add some style\n",
    "#####################\n",
    "\n",
    "plt.ylim(0, 1.3)\n",
    "plt.xlim(0, None)\n",
    "\n",
    "plt.ylabel(r\"$\\nu\\ \\ /\\,nM\\: s^{-1}$\")  \n",
    "plt.xlabel(r\"$[S]\\ \\ /\\,\\mu M$\")\n",
    "plt.title(\"Michaelis-Menten Plot\")\n",
    "\n",
    "######################\n",
    "### Display and export the plot\n",
    "#####################\n",
    "\n",
    "#plt.savefig(\"MM_plot_err.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Error in LB Plots\n",
    "\n",
    "The code below will apply an amount of random error to the data in the problem and then I will steal all the code for the LB linear fit and plot from above and use it again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "########################################################################\n",
    "### Copied the code from above for the LB linear fit. Cut and paste is your friend.\n",
    "########################################################################\n",
    "\n",
    "#####################################\n",
    "### Explore Effect of Error\n",
    "#####################################\n",
    "\n",
    "### We start with the x,y data entered at the top of this document\n",
    "### Set an error range and then randomly add or subtract the error\n",
    "\n",
    "experimental_error = 0.05   ### error will be +/- this value\n",
    "\n",
    "x2 = x   ## We want to copy the orginal data so that every time we rerun this\n",
    "y2 = y   ##  block of code we are starting agaion with the unchanged original data\n",
    "\n",
    "true_slope = 4.57   ### Results of LB curve fit\n",
    "true_intercept = 0.88\n",
    "\n",
    "\n",
    "number_of_points = len(y)\n",
    "random_values = np.random.randn(number_of_points) * experimental_error\n",
    "y2 = y2 + random_values\n",
    "\n",
    "########################################################################\n",
    "### Code for MM Plot from Above. Stolen and reused.\n",
    "########################################################################\n",
    "\n",
    "\n",
    "####################################\n",
    "### Perform the curve fit\n",
    "####################################\n",
    "\n",
    "x2_lb = 1 / x2\n",
    "y2_lb = 1 / y2\n",
    "\n",
    "\n",
    "\n",
    "params, stats = curve_fit(linear, x2_lb, y2_lb)   ## two objects are returned\n",
    "\n",
    "####################################\n",
    "### Interpret the results\n",
    "####################################\n",
    "\n",
    "slope, intercept = params   ### pull out the two values in the params object\n",
    "\n",
    "perr = np.sqrt(np.diag(stats))        ### convert covariance matrix to stdev values\n",
    "stdev_slope, stdev_intercept = perr   ### pull out the two stdev values \n",
    "\n",
    "slope_u = un.ufloat(slope,stdev_slope)               ## create a value with uncertainty built in\n",
    "intercept_u = un.ufloat(intercept,stdev_intercept)  \n",
    "\n",
    "v_max = 1 / intercept_u\n",
    "KM = v_max * slope_u\n",
    "\n",
    "print(f\"The Vmax is {v_max:0.3f} uM/s\")         ## Observe that the single variable now combines the value and the uncertainty\n",
    "print(f\"The KM is {KM:0.3f} mM\")\n",
    "print()\n",
    "\n",
    "list_LB_Vmax.append(unp.nominal_values(v_max))\n",
    "list_LB_KM.append(unp.nominal_values(KM))\n",
    "\n",
    "\n",
    "################################\n",
    "### make a list of x values from zero to the end of the line\n",
    "################################\n",
    "\n",
    "x_fit = np.linspace(0, np.max(x2_lb), 100)  ## 100 points from 0 to the highest value on LB plot x-axis\n",
    "\n",
    "################################\n",
    "### Feed that list into the function for the line fit\n",
    "################################\n",
    "\n",
    "y_fit = linear(x_fit, slope, intercept)\n",
    "\n",
    "######################\n",
    "### Create an empty plot\n",
    "#####################\n",
    "\n",
    "plt.rcdefaults()           \n",
    "plt.figure(figsize=(5,4))  \n",
    "\n",
    "######################\n",
    "### Plot the data and the curve fit line\n",
    "#####################\n",
    "\n",
    "plt.plot(x2_lb, y2_lb, \"ko\")\n",
    "plt.plot(x_fit, y_fit, \"k-\")   \n",
    "                                                                  ######################################\n",
    "plt.plot(x_fit, linear(x_fit, true_slope, true_intercept), \"r-\")  ### Add in \"ghost line\" for original data\n",
    "                                                                  ######################################\n",
    "######################\n",
    "### Add some style\n",
    "#####################\n",
    "\n",
    "plt.ylim(0, None)\n",
    "plt.xlim(0, None)\n",
    "\n",
    "plt.ylabel(r\"$1\\,/\\,(\\nu\\ /nM\\; s^{-1})$\")\n",
    "plt.xlabel(r\"$1\\,/\\;([S]\\ /\\mu M)$\")\n",
    "plt.title(\"Lineweaver-Burke Plot\")\n",
    "\n",
    "######################\n",
    "### Display and export the plot\n",
    "#####################\n",
    "\n",
    "#plt.savefig(\"LB_plot_err.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Results\n",
    "\n",
    "We have been collecting the results of each execution of the code blocks above. Now we can get the average value and the standard deviation for the values we have observed in each plot. How do they compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#### Take the collected results and report mean and stdev \n",
    "\n",
    "print_lists = True  ### True or False   ### Are we printing the lists?\n",
    "\n",
    "## round the results for neat printing.\n",
    "\n",
    "### Summary of MM trials\n",
    "\n",
    "if print_lists:            ### If we want to print the lists\n",
    "    print(np.round(list_MM_Vmax,2))\n",
    "    print(np.round(list_MM_KM,2))\n",
    "    print()\n",
    "\n",
    "print(f\"MM Vmax  {un.ufloat(np.mean(list_MM_Vmax),np.std(list_MM_Vmax)):0.3f}\")\n",
    "print(f\"MM KM    {un.ufloat(np.mean(list_MM_KM),np.std(list_MM_KM)):0.3f}\")\n",
    "print()\n",
    "\n",
    "### Summary of LB trials\n",
    "\n",
    "if False:                  ### If we need to remove an outlier\n",
    "    list_LB_Vmax.pop(5)\n",
    "    list_LB_KM.pop(5)\n",
    "\n",
    "if print_lists:            ### If we want to print the lists\n",
    "    print(np.round(list_LB_Vmax, 2))\n",
    "    print(np.round(list_LB_KM, 2))\n",
    "    print()\n",
    "\n",
    "print(f\"LB Vmax  {un.ufloat(np.mean(list_LB_Vmax),np.std(list_LB_Vmax)):0.3f}\")\n",
    "print(f\"LB KM    {un.ufloat(np.mean(list_LB_KM),np.std(list_LB_KM)):0.3f}\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Linear Methods\n",
    "\n",
    "There are two other common approaches to linearizing the Michaelis-Menten equation: The Eadie-Hofstee plot and the Hanes-Woolf plot.\n",
    "\n",
    "### Eadie-Hofstee\n",
    "\n",
    "The Eadie-Hofstee plot is...\n",
    "\n",
    "$$ \\nu = -K_M\\frac{\\nu}{[S]} + Vmax $$\n",
    "\n",
    "So we will have a x-axis of $\\nu / [S]$ and a y-axis of $\\nu$. The y-intecept will be $V_{max}$ and the slope is the negative value of $K_M$.\n",
    "\n",
    "Let us steal the code above and change it so that we are plotting the Eadie-Hofstee plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "### create blank lists to store our random results \n",
    "list_EH_Vmax = []\n",
    "list_EH_KM = []\n",
    "list_HW_Vmax = []\n",
    "list_HW_KM = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "########################################################################\n",
    "### Copied the code from above for the LB linear fit. Cut and paste is your friend.\n",
    "########################################################################\n",
    "\n",
    "#####################################\n",
    "### Explore Effect of Error\n",
    "#####################################\n",
    "\n",
    "### We start with the x,y data entered at the top of this document\n",
    "### Set an error range and then randomly add or subtract the error\n",
    "\n",
    "experimental_error = 0.05   ### error will be +/- this value\n",
    "\n",
    "x2 = x   ## We want to copy the orginal data so that every time we rerun this\n",
    "y2 = y     ##  block of code we are starting agaion with the unchanged original data\n",
    "\n",
    "true_v_max = 1.123   ### Results of MM curve fit\n",
    "true_KM = 5.002\n",
    "\n",
    "\n",
    "number_of_points = len(y)\n",
    "random_values = np.random.randn(number_of_points) * experimental_error\n",
    "y2 = y2 + random_values\n",
    "\n",
    "########################################################################\n",
    "### Code for MM Plot from Above. Stolen and reused.\n",
    "########################################################################\n",
    "\n",
    "\n",
    "####################################\n",
    "### Perform the curve fit\n",
    "####################################\n",
    "\n",
    "x2_eh = y2 / x2\n",
    "y2_eh = y2\n",
    "\n",
    "\n",
    "\n",
    "params, stats = curve_fit(linear, x2_eh, y2_eh)   ## two objects are returned\n",
    "\n",
    "####################################\n",
    "### Interpret the results\n",
    "####################################\n",
    "\n",
    "slope, intercept = params   ### pull out the two values in the params object\n",
    "\n",
    "perr = np.sqrt(np.diag(stats))        ### convert covariance matrix to stdev values\n",
    "stdev_slope, stdev_intercept = perr   ### pull out the two stdev values \n",
    "\n",
    "slope_u = un.ufloat(slope,stdev_slope)               ## create a value with uncertainty built in\n",
    "intercept_u = un.ufloat(intercept,stdev_intercept)  \n",
    "\n",
    "v_max = intercept_u\n",
    "KM = - slope_u\n",
    "\n",
    "print(f\"The Vmax is {v_max:0.3f} uM/s\")         ## Observe that the single variable now combines the value and the uncertainty\n",
    "print(f\"The KM is {KM:0.3f} mM\")\n",
    "print()\n",
    "\n",
    "list_EH_Vmax.append(unp.nominal_values(v_max))\n",
    "list_EH_KM.append(unp.nominal_values(KM))\n",
    "\n",
    "\n",
    "################################\n",
    "### make a list of x values from zero to the end of the line\n",
    "################################\n",
    "\n",
    "x_fit = np.linspace(0, np.max(x2_eh), 100)  ## 100 points from 0 to the highest value on LB plot x-axis\n",
    "\n",
    "################################\n",
    "### Feed that list into the function for the line fit\n",
    "################################\n",
    "\n",
    "y_fit = linear(x_fit, slope, intercept)\n",
    "\n",
    "######################\n",
    "### Create an empty plot\n",
    "#####################\n",
    "\n",
    "plt.rcdefaults()           \n",
    "plt.figure(figsize=(5,4))  \n",
    "\n",
    "######################\n",
    "### Plot the data and the curve fit line\n",
    "#####################\n",
    "\n",
    "plt.plot(x2_eh, y2_eh, \"ko\")\n",
    "plt.plot(x_fit, y_fit, \"k-\")   \n",
    "                                                                  ######################################\n",
    "plt.plot(x_fit, linear(x_fit, -true_KM, true_v_max), \"r-\")  ### Add in \"ghost line\" for original data\n",
    "                                                                  ######################################\n",
    "######################\n",
    "### Add some style\n",
    "#####################\n",
    "\n",
    "plt.ylim(0, 1.3)\n",
    "plt.xlim(0, None)\n",
    "\n",
    "plt.ylabel(r\"$\\nu$\")\n",
    "plt.xlabel(r\"$\\nu\\,/\\;[S]$\")\n",
    "plt.title(\"Eadie-Hofstee Plot\")\n",
    "\n",
    "######################\n",
    "### Display and export the plot\n",
    "#####################\n",
    "\n",
    "#plt.savefig(\"EH_plot_err.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Hanes-Woolf\n",
    "\n",
    "The Hanes-Woolf plot is...\n",
    "\n",
    "$$ \\frac{[S]}{\\nu} = \\frac{1}{V_{max}}[S] + \\frac{K_M}{V_{max}} $$\n",
    "\n",
    "So we will have a x-axis of $[S]$ and a y-axis of $[S]/ \\nu$. The y-intecept will be $K_M / V_{max}$ and the slope is the negative value of $1 / V_{max}$.\n",
    "\n",
    "Let us steal the code above and change it so that we are plotting the Hanes-Woolf plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "########################################################################\n",
    "### Copied the code from above for the LB linear fit. Cut and paste is your friend.\n",
    "########################################################################\n",
    "\n",
    "#####################################\n",
    "### Explore Effect of Error\n",
    "#####################################\n",
    "\n",
    "### We start with the x,y data entered at the top of this document\n",
    "### Set an error range and then randomly add or subtract the error\n",
    "\n",
    "experimental_error = 0.05   ### error will be +/- this value\n",
    "\n",
    "x2 = x   ## We want to copy the orginal data so that every time we rerun this\n",
    "y2 = y     ##  block of code we are starting agaion with the unchanged original data\n",
    "\n",
    "true_v_max = 1.123   ### Results of MM curve fit\n",
    "true_KM = 5.002\n",
    "\n",
    "\n",
    "number_of_points = len(y)\n",
    "random_values = np.random.randn(number_of_points) * experimental_error\n",
    "y2 = y2 + random_values\n",
    "\n",
    "########################################################################\n",
    "### Code for MM Plot from Above. Stolen and reused.\n",
    "########################################################################\n",
    "\n",
    "\n",
    "####################################\n",
    "### Perform the curve fit\n",
    "####################################\n",
    "\n",
    "x2_hw = x2\n",
    "y2_hw = x2 / y2\n",
    "\n",
    "\n",
    "\n",
    "params, stats = curve_fit(linear, x2_hw, y2_hw)   ## two objects are returned\n",
    "\n",
    "####################################\n",
    "### Interpret the results\n",
    "####################################\n",
    "\n",
    "slope, intercept = params   ### pull out the two values in the params object\n",
    "\n",
    "perr = np.sqrt(np.diag(stats))        ### convert covariance matrix to stdev values\n",
    "stdev_slope, stdev_intercept = perr   ### pull out the two stdev values \n",
    "\n",
    "slope_u = un.ufloat(slope,stdev_slope)               ## create a value with uncertainty built in\n",
    "intercept_u = un.ufloat(intercept,stdev_intercept)  \n",
    "\n",
    "v_max = 1 / slope_u\n",
    "KM = intercept_u / slope_u\n",
    "\n",
    "print(f\"The Vmax is {v_max:0.3f} uM/s\")         ## Observe that the single variable now combines the value and the uncertainty\n",
    "print(f\"The KM is {KM:0.3f} mM\")\n",
    "print()\n",
    "\n",
    "list_HW_Vmax.append(unp.nominal_values(v_max))\n",
    "list_HW_KM.append(unp.nominal_values(KM))\n",
    "\n",
    "\n",
    "################################\n",
    "### make a list of x values from zero to the end of the line\n",
    "################################\n",
    "\n",
    "x_fit = np.linspace(0, np.max(x2_hw), 100)  ## 100 points from 0 to the highest value on LB plot x-axis\n",
    "\n",
    "################################\n",
    "### Feed that list into the function for the line fit\n",
    "################################\n",
    "\n",
    "y_fit = linear(x_fit, slope, intercept)\n",
    "\n",
    "######################\n",
    "### Create an empty plot\n",
    "#####################\n",
    "\n",
    "plt.rcdefaults()           \n",
    "plt.figure(figsize=(5,4))  \n",
    "\n",
    "######################\n",
    "### Plot the data and the curve fit line\n",
    "#####################\n",
    "\n",
    "plt.plot(x2_hw, y2_hw, \"ko\")\n",
    "plt.plot(x_fit, y_fit, \"k-\")   \n",
    "                                                                  ######################################\n",
    "plt.plot(x_fit, linear(x_fit, 1/true_v_max, true_KM/true_v_max), \"r-\")  ### Add in \"ghost line\" for original data\n",
    "                                                                  ######################################\n",
    "######################\n",
    "### Add some style\n",
    "#####################\n",
    "\n",
    "plt.ylim(0, None)\n",
    "plt.xlim(0, None)\n",
    "\n",
    "plt.ylabel(r\"$[S] \\; / \\; \\nu$\")\n",
    "plt.xlabel(r\"$[S]$\")\n",
    "plt.title(\"Hanes-Woolf Plot\")\n",
    "\n",
    "######################\n",
    "### Display and export the plot\n",
    "#####################\n",
    "\n",
    "#plt.savefig(\"HW_plot_err.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Results\n",
    "\n",
    "We have been collecting the results of each execution of the code blocks above. Now we can get the average value and the standard deviation for the values we have observed in each plot. How do they compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#### Take the collected results and report mean and stdev \n",
    "\n",
    "print_lists = True  ### True or False   ### Are we printing the lists?\n",
    "\n",
    "## round the results for neat printing.\n",
    "\n",
    "### Summary of EH trials\n",
    "\n",
    "if print_lists:            ### If we want to print the lists\n",
    "    print(np.round(list_EH_Vmax,2))\n",
    "    print(np.round(list_EH_KM,2))\n",
    "    print()\n",
    "\n",
    "print(f\"EH Vmax  {un.ufloat(np.mean(list_EH_Vmax),np.std(list_EH_Vmax)):0.3f}\")\n",
    "print(f\"EH KM    {un.ufloat(np.mean(list_EH_KM),np.std(list_EH_KM)):0.3f}\")\n",
    "print()\n",
    "\n",
    "### Summary of HW trials\n",
    "\n",
    "if False:                  ### If we need to remove an outlier\n",
    "    list_HW_Vmax.pop(5)\n",
    "    list_HW_KM.pop(5)\n",
    "\n",
    "if print_lists:            ### If we want to print the lists\n",
    "    print(np.round(list_HW_Vmax, 2))\n",
    "    print(np.round(list_HW_KM, 2))\n",
    "    print()\n",
    "\n",
    "print(f\"HW Vmax  {un.ufloat(np.mean(list_HW_Vmax),np.std(list_HW_Vmax)):0.3f}\")\n",
    "print(f\"HW KM    {un.ufloat(np.mean(list_HW_KM),np.std(list_HW_KM)):0.3f}\")\n",
    "print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
